{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75473004-a5f9-446e-98bc-93c889f58e0b",
   "metadata": {},
   "source": [
    "# 2025-02-12\n",
    "## Plan\n",
    "- Get the tiny shakespeare dataset\n",
    "- Build encoding and decoding logic\n",
    "- Visualize what context_size is\n",
    "- Train test/ val split\n",
    "- Buld get_batch function\n",
    "- Build bigram model that uses an embedding of vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ecf0ca37-498e-4c26-9876-e3f765103145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import requests as r\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1e688c-cb25-4f34-a72d-b17393b8b556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "data = r.get(dataset_url)\n",
    "data = data.text\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be242014-1769-4a3b-a758-2b2a83f788b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 47]\n",
      "hiiii\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(set(list(data)))\n",
    "c_to_i = { c: i for i, c in enumerate(unique_chars) }\n",
    "i_to_c = { i: c for i, c in enumerate(unique_chars) }\n",
    "\n",
    "def encode(chars):\n",
    "    return [c_to_i[char] for char in chars]\n",
    "\n",
    "def decode(ints):\n",
    "    return ''.join(list(i_to_c[i] for i in ints))\n",
    "\n",
    "print(encode(\"hiii\"))\n",
    "print(decode(encode(\"hiiii\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d29e13bd-1907-4063-8a11-c2f70c71157e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56,  ..., 45,  8,  0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = t.LongTensor(encode(data))\n",
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94ba9e88-5218-4a8a-9222-9c8511ec78ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60b0465b-f6b0-4145-a63e-e71b76fe58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context for 47 is tensor([18])\n",
      "Context for 56 is tensor([18, 47])\n",
      "Context for 57 is tensor([18, 47, 56])\n",
      "Context for 58 is tensor([18, 47, 56, 57])\n",
      "Context for 1 is tensor([18, 47, 56, 57, 58])\n",
      "Context for 15 is tensor([18, 47, 56, 57, 58,  1])\n",
      "Context for 47 is tensor([18, 47, 56, 57, 58,  1, 15])\n",
      "Context for 58 is tensor([18, 47, 56, 57, 58,  1, 15, 47])\n"
     ]
    }
   ],
   "source": [
    "context_size = 8\n",
    "x = data_tensor[0:context_size+1]\n",
    "\n",
    "for i in range(1, len(x)):\n",
    "    print(f\"Context for {x[i]} is {x[:i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6639b7f-91b7-4f3e-9f4c-05681444db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(data_tensor))\n",
    "train, test = data_tensor[:num_train], data_tensor[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e2a0d90-b65c-4d28-95c9-d54efd4f018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892315, 223079)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26b099b9-8da7-4449-a6b0-5c2602ee60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56,  ..., 39, 58,  1]),\n",
       " tensor([63, 53, 59,  ..., 45,  8,  0]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9e32d50-63db-46cb-9050-27718dc029da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 19, 24, 27, 33, 15, 17, 31],\n",
       "         [41, 53, 59, 57, 47, 52,  1, 22],\n",
       "         [59, 47, 58, 57,  1, 46, 47, 58],\n",
       "         [42,  1, 44, 43, 58, 41, 46,  1]]),\n",
       " tensor([[19, 24, 27, 33, 15, 17, 31, 32],\n",
       "         [53, 59, 57, 47, 52,  1, 22, 59],\n",
       "         [47, 58, 57,  1, 46, 47, 58, 46],\n",
       "         [ 1, 44, 43, 58, 41, 46,  1, 63]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    to_batch = train if split == \"train\" else test\n",
    "    batch_start_idx = t.randint(len(to_batch) - context_size, (4, ))\n",
    "    x = t.stack([to_batch[i:i+context_size] for i in batch_start_idx])\n",
    "    y = t.stack([to_batch[i+1:i+1+context_size] for i in batch_start_idx])\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d310820a-8763-408d-9bab-d7f344c4bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Context for 19 is tensor([], dtype=torch.int64)\n",
      "Batch 0: Context for 24 is tensor([0])\n",
      "Batch 0: Context for 27 is tensor([ 0, 19])\n",
      "Batch 0: Context for 33 is tensor([ 0, 19, 24])\n",
      "Batch 0: Context for 15 is tensor([ 0, 19, 24, 27])\n",
      "Batch 0: Context for 17 is tensor([ 0, 19, 24, 27, 33])\n",
      "Batch 0: Context for 31 is tensor([ 0, 19, 24, 27, 33, 15])\n",
      "Batch 0: Context for 32 is tensor([ 0, 19, 24, 27, 33, 15, 17])\n",
      "Batch 1: Context for 53 is tensor([], dtype=torch.int64)\n",
      "Batch 1: Context for 59 is tensor([41])\n",
      "Batch 1: Context for 57 is tensor([41, 53])\n",
      "Batch 1: Context for 47 is tensor([41, 53, 59])\n",
      "Batch 1: Context for 52 is tensor([41, 53, 59, 57])\n",
      "Batch 1: Context for 1 is tensor([41, 53, 59, 57, 47])\n",
      "Batch 1: Context for 22 is tensor([41, 53, 59, 57, 47, 52])\n",
      "Batch 1: Context for 59 is tensor([41, 53, 59, 57, 47, 52,  1])\n",
      "Batch 2: Context for 47 is tensor([], dtype=torch.int64)\n",
      "Batch 2: Context for 58 is tensor([59])\n",
      "Batch 2: Context for 57 is tensor([59, 47])\n",
      "Batch 2: Context for 1 is tensor([59, 47, 58])\n",
      "Batch 2: Context for 46 is tensor([59, 47, 58, 57])\n",
      "Batch 2: Context for 47 is tensor([59, 47, 58, 57,  1])\n",
      "Batch 2: Context for 58 is tensor([59, 47, 58, 57,  1, 46])\n",
      "Batch 2: Context for 46 is tensor([59, 47, 58, 57,  1, 46, 47])\n",
      "Batch 3: Context for 1 is tensor([], dtype=torch.int64)\n",
      "Batch 3: Context for 44 is tensor([42])\n",
      "Batch 3: Context for 43 is tensor([42,  1])\n",
      "Batch 3: Context for 58 is tensor([42,  1, 44])\n",
      "Batch 3: Context for 41 is tensor([42,  1, 44, 43])\n",
      "Batch 3: Context for 46 is tensor([42,  1, 44, 43, 58])\n",
      "Batch 3: Context for 1 is tensor([42,  1, 44, 43, 58, 41])\n",
      "Batch 3: Context for 63 is tensor([42,  1, 44, 43, 58, 41, 46])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx in range(batch_size):\n",
    "    for t_idx in range(context_size):\n",
    "        print(f\"Batch {batch_idx}: Context for {y[batch_idx, t_idx]} is {x[batch_idx, :t_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5adb380d-1f39-4a26-b927-23c4c1bef304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.vocab_embedding_dict = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # I don't love how this function returns a different shape for logits depending on targets\n",
    "        # x: (B, T)\n",
    "        # targets: (B, T)\n",
    "        logits = self.vocab_embedding_dict(x) # (B, T, C)\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # (B* T, C)\n",
    "            targets = targets.view(B*T) # (B*T, 1)\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idxs, max_num_tokens):\n",
    "        # do one step of idxs (B, T) until max tokens\n",
    "        # that means you do a forward pass, and pick the max probability\n",
    "        # -ln(p) lower => p is higher, sanity check for p = 1 :check:\n",
    "        \n",
    "        for i in range(max_num_tokens):\n",
    "            logits, _ = self(idxs)\n",
    "            # get the logits of the last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            # get the max\n",
    "            probs = nn.functional.softmax(logits, dim=-1) # (B, C)\n",
    "            idx_next = t.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idxs = t.cat([idxs, idx_next], dim=1) # (B, T+ 1)\n",
    "        return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c81e8f5e-5499-47f9-81de-24b666df6e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3907, -0.2744,  0.2176,  ..., -2.2814,  1.7432, -0.6710],\n",
       "         [ 0.3483, -0.2885,  0.0237,  ..., -0.4732,  0.5566,  1.4295],\n",
       "         [ 0.5494, -0.5782, -0.3410,  ...,  1.4509, -0.3217, -0.7092],\n",
       "         ...,\n",
       "         [-0.1415,  0.6276,  0.2061,  ..., -0.5163,  1.2369, -1.5646],\n",
       "         [ 0.1698, -1.7079,  1.5011,  ...,  1.5102,  0.3420, -0.6705],\n",
       "         [-0.6856, -0.5750, -0.0708,  ...,  1.1784,  0.9538,  1.7870]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(4.4908, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BigramLanguageModel(len(i_to_c))\n",
    "model(x, y) # expect loss of around -ln(1/vocab_size) negative log prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d3a0ce0-c874-420c-bce5-3c68460592a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1744])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected loss\n",
    "-t.log(t.Tensor([1 / len(i_to_c)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79290479-bc92-49b0-a7be-a2bbc3461fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 19, 24, 27, 33, 15, 17, 31, 35, 18, 33,  8],\n",
       "        [41, 53, 59, 57, 47, 52,  1, 22, 63, 16, 44, 43],\n",
       "        [59, 47, 58, 57,  1, 46, 47, 58, 11,  3, 59, 61],\n",
       "        [42,  1, 44, 43, 58, 41, 46,  1,  6, 48, 17, 47]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(x, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f173c422-9e31-47b3-beab-51a165ef5bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 24, 27, 33, 15, 17, 31, 32],\n",
       "        [53, 59, 57, 47, 52,  1, 22, 59],\n",
       "        [47, 58, 57,  1, 46, 47, 58, 46],\n",
       "        [ 1, 44, 43, 58, 41, 46,  1, 63]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db8739-7d5a-4c6f-ace4-5147e4e9de97",
   "metadata": {},
   "source": [
    "# 2025-02-13\n",
    "## Plan\n",
    "- Get the computed forward pass and decode it\n",
    "- Write a training loop with the Adam optimizer\n",
    "- Move everything to a script\n",
    "- Write a self attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d2e70b7-42bf-4812-894e-c6d214de4b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 35, 34, 24, 33, 28,  5, 64, 38, 39, 50,  3, 14, 26, 49, 24, 58, 44,\n",
       "         44, 45, 36, 28, 45, 38, 26,  6, 30, 24, 43, 36,  1, 61, 43, 25, 17, 13,\n",
       "          8, 62, 20, 26, 10, 11, 17, 36, 62, 31,  2, 49,  0, 38, 47, 26, 64, 53,\n",
       "         15, 28, 54, 64, 47, 53, 26, 18, 57, 26, 17,  9, 11, 39,  7,  5, 11, 63,\n",
       "         48, 40, 61, 32, 33, 39, 33, 11, 64, 45, 20, 59,  3, 56, 10, 22, 64, 28,\n",
       "          8, 36, 28, 57, 27, 19, 29, 32, 53,  9, 63]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_idxs = t.zeros((1,1), dtype=t.long)\n",
    "tokens_to_generate = 1000\n",
    "idxs = model.generate(zero_idxs, tokens_to_generate)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69a741d9-c386-4dd5-abe2-a3538aa79e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWVLUP'zZal$BNkLtffgXPgZN,RLeX weMEA.xHN:;EXxS!k\\nZiNzoCPpzioNFsNE3;a-';yjbwTUaU;zgHu$r:JzP.XPsOGQTo3y\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(idxs[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "037c68b3-b863-4fe6-a219-4a7ab17c3137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nKvACBHPZ &$:alsMGrvZ'cM\\nfWV&bR,,LQJFrMlRZNqetwPIihwwH&&Dy &Rk;ugA'jCLGJ&$ zKjqtVePNHPojpDfD!zYqyjRme\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one liner\n",
    "decode(model.generate(t.zeros((1,1), dtype=t.long), tokens_to_generate)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17a955ed-d1a5-4841-87fc-834decd45017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.6867167949676514\n",
      "loss: 2.3886053562164307\n",
      "loss: 2.1273231506347656\n",
      "loss: 2.8246164321899414\n",
      "loss: 2.5422158241271973\n",
      "loss: 2.576198101043701\n",
      "loss: 2.6322779655456543\n",
      "loss: 2.833005666732788\n",
      "loss: 2.434377431869507\n",
      "loss: 2.2865514755249023\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    x, y = get_batch('train')\n",
    "    _, loss = model.forward(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19841974-f11a-4966-84a3-5e24f6c6be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An\n",
      "\n",
      "Pou'll thay; CEESANRD m the;\n",
      "AUS: toigof cke feniren; yof ioll d as aghothipl,\n",
      "AMENoat tlid toung bur hous be w'den a s?\n",
      "HAs hetrware.\n",
      "Maltonen I py ovoung teang burger.\n",
      "Wh at ar cr m thetu angleng s Inowive wen minoutwis, BRinethis f m nor ERDe or s, hy wharorokn dothel' houe he ot finsor,\n",
      "\n",
      "T:\n",
      "\n",
      "AUTithesod w de hont t houlyouly t sthar:\n",
      "ELINoun st y my ur marthe thithy col he fiote g, wit bil, plert s\n",
      "\n",
      "LADr k ivenghyotinges whoure;\n",
      "\n",
      "Fithishireaingupovemprad; ca ano me, stondo s batheeands:\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "tokens_to_generate = 500\n",
    "print(decode(model.generate(t.zeros((1,1), dtype=t.long), tokens_to_generate)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a99a33-8f08-4ac3-bfe4-dcd4d7a53508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
