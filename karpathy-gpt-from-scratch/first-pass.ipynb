{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75473004-a5f9-446e-98bc-93c889f58e0b",
   "metadata": {},
   "source": [
    "# 2025-02-12\n",
    "## Plan\n",
    "- Get the tiny shakespeare dataset\n",
    "- Build encoding and decoding logic\n",
    "- Visualize what context_size is\n",
    "- Train test/ val split\n",
    "- Buld get_batch function\n",
    "- Build bigram model that uses an embedding of vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf0ca37-498e-4c26-9876-e3f765103145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Documents/projects/transformers-deep-dive/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import requests as r\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1e688c-cb25-4f34-a72d-b17393b8b556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "data = r.get(dataset_url)\n",
    "data = data.text\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be242014-1769-4a3b-a758-2b2a83f788b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 47]\n",
      "hiiii\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(set(list(data)))\n",
    "c_to_i = { c: i for i, c in enumerate(unique_chars) }\n",
    "i_to_c = { i: c for i, c in enumerate(unique_chars) }\n",
    "\n",
    "def encode(chars):\n",
    "    return [c_to_i[char] for char in chars]\n",
    "\n",
    "def decode(ints):\n",
    "    return ''.join(list(i_to_c[i] for i in ints))\n",
    "\n",
    "print(encode(\"hiii\"))\n",
    "print(decode(encode(\"hiiii\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29e13bd-1907-4063-8a11-c2f70c71157e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56,  ..., 45,  8,  0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = t.LongTensor(encode(data))\n",
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ba9e88-5218-4a8a-9222-9c8511ec78ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b0465b-f6b0-4145-a63e-e71b76fe58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context for 47 is tensor([18])\n",
      "Context for 56 is tensor([18, 47])\n",
      "Context for 57 is tensor([18, 47, 56])\n",
      "Context for 58 is tensor([18, 47, 56, 57])\n",
      "Context for 1 is tensor([18, 47, 56, 57, 58])\n",
      "Context for 15 is tensor([18, 47, 56, 57, 58,  1])\n",
      "Context for 47 is tensor([18, 47, 56, 57, 58,  1, 15])\n",
      "Context for 58 is tensor([18, 47, 56, 57, 58,  1, 15, 47])\n"
     ]
    }
   ],
   "source": [
    "context_size = 8\n",
    "x = data_tensor[0:context_size+1]\n",
    "\n",
    "for i in range(1, len(x)):\n",
    "    print(f\"Context for {x[i]} is {x[:i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6639b7f-91b7-4f3e-9f4c-05681444db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(data_tensor))\n",
    "train, test = data_tensor[:num_train], data_tensor[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2a0d90-b65c-4d28-95c9-d54efd4f018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892315, 223079)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b099b9-8da7-4449-a6b0-5c2602ee60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56,  ..., 39, 58,  1]),\n",
       " tensor([63, 53, 59,  ..., 45,  8,  0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e32d50-63db-46cb-9050-27718dc029da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50, 43,  6,  0, 35, 46, 43, 56],\n",
       "         [63,  0, 40, 43, 52, 41, 46, 43],\n",
       "         [61, 53, 59, 50, 42,  1, 58, 43],\n",
       "         [ 1, 46, 53, 52, 53, 59, 56,  5]]),\n",
       " tensor([[43,  6,  0, 35, 46, 43, 56, 43],\n",
       "         [ 0, 40, 43, 52, 41, 46, 43, 56],\n",
       "         [53, 59, 50, 42,  1, 58, 43, 50],\n",
       "         [46, 53, 52, 53, 59, 56,  5, 42]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    to_batch = train if split == \"train\" else test\n",
    "    batch_start_idx = t.randint(len(to_batch) - context_size, (4, ))\n",
    "    x = t.stack([to_batch[i:i+context_size] for i in batch_start_idx])\n",
    "    y = t.stack([to_batch[i+1:i+1+context_size] for i in batch_start_idx])\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d310820a-8763-408d-9bab-d7f344c4bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Context for 19 is tensor([], dtype=torch.int64)\n",
      "Batch 0: Context for 24 is tensor([0])\n",
      "Batch 0: Context for 27 is tensor([ 0, 19])\n",
      "Batch 0: Context for 33 is tensor([ 0, 19, 24])\n",
      "Batch 0: Context for 15 is tensor([ 0, 19, 24, 27])\n",
      "Batch 0: Context for 17 is tensor([ 0, 19, 24, 27, 33])\n",
      "Batch 0: Context for 31 is tensor([ 0, 19, 24, 27, 33, 15])\n",
      "Batch 0: Context for 32 is tensor([ 0, 19, 24, 27, 33, 15, 17])\n",
      "Batch 1: Context for 53 is tensor([], dtype=torch.int64)\n",
      "Batch 1: Context for 59 is tensor([41])\n",
      "Batch 1: Context for 57 is tensor([41, 53])\n",
      "Batch 1: Context for 47 is tensor([41, 53, 59])\n",
      "Batch 1: Context for 52 is tensor([41, 53, 59, 57])\n",
      "Batch 1: Context for 1 is tensor([41, 53, 59, 57, 47])\n",
      "Batch 1: Context for 22 is tensor([41, 53, 59, 57, 47, 52])\n",
      "Batch 1: Context for 59 is tensor([41, 53, 59, 57, 47, 52,  1])\n",
      "Batch 2: Context for 47 is tensor([], dtype=torch.int64)\n",
      "Batch 2: Context for 58 is tensor([59])\n",
      "Batch 2: Context for 57 is tensor([59, 47])\n",
      "Batch 2: Context for 1 is tensor([59, 47, 58])\n",
      "Batch 2: Context for 46 is tensor([59, 47, 58, 57])\n",
      "Batch 2: Context for 47 is tensor([59, 47, 58, 57,  1])\n",
      "Batch 2: Context for 58 is tensor([59, 47, 58, 57,  1, 46])\n",
      "Batch 2: Context for 46 is tensor([59, 47, 58, 57,  1, 46, 47])\n",
      "Batch 3: Context for 1 is tensor([], dtype=torch.int64)\n",
      "Batch 3: Context for 44 is tensor([42])\n",
      "Batch 3: Context for 43 is tensor([42,  1])\n",
      "Batch 3: Context for 58 is tensor([42,  1, 44])\n",
      "Batch 3: Context for 41 is tensor([42,  1, 44, 43])\n",
      "Batch 3: Context for 46 is tensor([42,  1, 44, 43, 58])\n",
      "Batch 3: Context for 1 is tensor([42,  1, 44, 43, 58, 41])\n",
      "Batch 3: Context for 63 is tensor([42,  1, 44, 43, 58, 41, 46])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx in range(batch_size):\n",
    "    for t_idx in range(context_size):\n",
    "        print(f\"Batch {batch_idx}: Context for {y[batch_idx, t_idx]} is {x[batch_idx, :t_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5adb380d-1f39-4a26-b927-23c4c1bef304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.vocab_embedding_dict = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # I don't love how this function returns a different shape for logits depending on targets\n",
    "        # x: (B, T)\n",
    "        # targets: (B, T)\n",
    "        logits = self.vocab_embedding_dict(x) # (B, T, C)\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # (B* T, C)\n",
    "            targets = targets.view(B*T) # (B*T, 1)\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idxs, max_num_tokens):\n",
    "        # do one step of idxs (B, T) until max tokens\n",
    "        # that means you do a forward pass, and pick the max probability\n",
    "        # -ln(p) lower => p is higher, sanity check for p = 1 :check:\n",
    "        \n",
    "        for i in range(max_num_tokens):\n",
    "            logits, _ = self(idxs)\n",
    "            # get the logits of the last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            # get the max\n",
    "            probs = nn.functional.softmax(logits, dim=-1) # (B, C)\n",
    "            idx_next = t.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idxs = t.cat([idxs, idx_next], dim=1) # (B, T+ 1)\n",
    "        return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c81e8f5e-5499-47f9-81de-24b666df6e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3907, -0.2744,  0.2176,  ..., -2.2814,  1.7432, -0.6710],\n",
       "         [ 0.3483, -0.2885,  0.0237,  ..., -0.4732,  0.5566,  1.4295],\n",
       "         [ 0.5494, -0.5782, -0.3410,  ...,  1.4509, -0.3217, -0.7092],\n",
       "         ...,\n",
       "         [-0.1415,  0.6276,  0.2061,  ..., -0.5163,  1.2369, -1.5646],\n",
       "         [ 0.1698, -1.7079,  1.5011,  ...,  1.5102,  0.3420, -0.6705],\n",
       "         [-0.6856, -0.5750, -0.0708,  ...,  1.1784,  0.9538,  1.7870]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(4.4908, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BigramLanguageModel(len(i_to_c))\n",
    "model(x, y) # expect loss of around -ln(1/vocab_size) negative log prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d3a0ce0-c874-420c-bce5-3c68460592a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1744])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected loss\n",
    "-t.log(t.Tensor([1 / len(i_to_c)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79290479-bc92-49b0-a7be-a2bbc3461fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 19, 24, 27, 33, 15, 17, 31, 35, 18, 33,  8],\n",
       "        [41, 53, 59, 57, 47, 52,  1, 22, 63, 16, 44, 43],\n",
       "        [59, 47, 58, 57,  1, 46, 47, 58, 11,  3, 59, 61],\n",
       "        [42,  1, 44, 43, 58, 41, 46,  1,  6, 48, 17, 47]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(x, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f173c422-9e31-47b3-beab-51a165ef5bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 24, 27, 33, 15, 17, 31, 32],\n",
       "        [53, 59, 57, 47, 52,  1, 22, 59],\n",
       "        [47, 58, 57,  1, 46, 47, 58, 46],\n",
       "        [ 1, 44, 43, 58, 41, 46,  1, 63]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db8739-7d5a-4c6f-ace4-5147e4e9de97",
   "metadata": {},
   "source": [
    "# 2025-02-13\n",
    "## Plan\n",
    "- Get the computed forward pass and decode it\n",
    "- Write a training loop with the Adam optimizer\n",
    "- Move everything to a script\n",
    "- Write a self attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d2e70b7-42bf-4812-894e-c6d214de4b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 35, 34, 24, 33, 28,  5, 64, 38, 39, 50,  3, 14, 26, 49, 24, 58, 44,\n",
       "         44, 45, 36, 28, 45, 38, 26,  6, 30, 24, 43, 36,  1, 61, 43, 25, 17, 13,\n",
       "          8, 62, 20, 26, 10, 11, 17, 36, 62, 31,  2, 49,  0, 38, 47, 26, 64, 53,\n",
       "         15, 28, 54, 64, 47, 53, 26, 18, 57, 26, 17,  9, 11, 39,  7,  5, 11, 63,\n",
       "         48, 40, 61, 32, 33, 39, 33, 11, 64, 45, 20, 59,  3, 56, 10, 22, 64, 28,\n",
       "          8, 36, 28, 57, 27, 19, 29, 32, 53,  9, 63]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_idxs = t.zeros((1,1), dtype=t.long)\n",
    "tokens_to_generate = 1000\n",
    "idxs = model.generate(zero_idxs, tokens_to_generate)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69a741d9-c386-4dd5-abe2-a3538aa79e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWVLUP'zZal$BNkLtffgXPgZN,RLeX weMEA.xHN:;EXxS!k\\nZiNzoCPpzioNFsNE3;a-';yjbwTUaU;zgHu$r:JzP.XPsOGQTo3y\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(idxs[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "037c68b3-b863-4fe6-a219-4a7ab17c3137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nKvACBHPZ &$:alsMGrvZ'cM\\nfWV&bR,,LQJFrMlRZNqetwPIihwwH&&Dy &Rk;ugA'jCLGJ&$ zKjqtVePNHPojpDfD!zYqyjRme\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one liner\n",
    "decode(model.generate(t.zeros((1,1), dtype=t.long), tokens_to_generate)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17a955ed-d1a5-4841-87fc-834decd45017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.6867167949676514\n",
      "loss: 2.3886053562164307\n",
      "loss: 2.1273231506347656\n",
      "loss: 2.8246164321899414\n",
      "loss: 2.5422158241271973\n",
      "loss: 2.576198101043701\n",
      "loss: 2.6322779655456543\n",
      "loss: 2.833005666732788\n",
      "loss: 2.434377431869507\n",
      "loss: 2.2865514755249023\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    x, y = get_batch('train')\n",
    "    _, loss = model.forward(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19841974-f11a-4966-84a3-5e24f6c6be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An\n",
      "\n",
      "Pou'll thay; CEESANRD m the;\n",
      "AUS: toigof cke feniren; yof ioll d as aghothipl,\n",
      "AMENoat tlid toung bur hous be w'den a s?\n",
      "HAs hetrware.\n",
      "Maltonen I py ovoung teang burger.\n",
      "Wh at ar cr m thetu angleng s Inowive wen minoutwis, BRinethis f m nor ERDe or s, hy wharorokn dothel' houe he ot finsor,\n",
      "\n",
      "T:\n",
      "\n",
      "AUTithesod w de hont t houlyouly t sthar:\n",
      "ELINoun st y my ur marthe thithy col he fiote g, wit bil, plert s\n",
      "\n",
      "LADr k ivenghyotinges whoure;\n",
      "\n",
      "Fithishireaingupovemprad; ca ano me, stondo s batheeands:\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "tokens_to_generate = 500\n",
    "print(decode(model.generate(t.zeros((1,1), dtype=t.long), tokens_to_generate)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b080f1f-3069-4d59-8250-a85eb76c019b",
   "metadata": {},
   "source": [
    "Now to implement the attention blocks. First get some understanding of what we're trying to do\n",
    "Each word is trying to build context of the words around it\n",
    "simplest way is to average all teh tokens before you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009d749d-8834-4858-99f9-ea2dbfe33e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = t.rand(B, T, C)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a1f7f8d-3bfb-414d-b7f7-a4e4e9d4a322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6900, 0.3497],\n",
       "        [0.3722, 0.0837],\n",
       "        [0.7150, 0.2682],\n",
       "        [0.3834, 0.4518],\n",
       "        [0.3707, 0.3285],\n",
       "        [0.1733, 0.5982],\n",
       "        [0.8305, 0.3529],\n",
       "        [0.9904, 0.6499]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed99a27c-fe59-40a6-b4b0-b7673100b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg1 = []\n",
    "for batch in x:\n",
    "    avg1.append(t.stack([batch[:i + 1, :].sum(dim=0) / (i + 1) for i in range(len(x[0]))]))\n",
    "    \n",
    "avg1 = t.stack(avg1)\n",
    "avg1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98573a91-13e4-4e23-ac82-b0eeb7cfb5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6900, 0.3497],\n",
       "         [0.5311, 0.2167],\n",
       "         [0.5924, 0.2338],\n",
       "         [0.5401, 0.2883],\n",
       "         [0.5063, 0.2964],\n",
       "         [0.4508, 0.3467],\n",
       "         [0.5050, 0.3476],\n",
       "         [0.5657, 0.3854]]),\n",
       " tensor([[0.6900, 0.3497],\n",
       "         [0.3722, 0.0837],\n",
       "         [0.7150, 0.2682],\n",
       "         [0.3834, 0.4518],\n",
       "         [0.3707, 0.3285],\n",
       "         [0.1733, 0.5982],\n",
       "         [0.8305, 0.3529],\n",
       "         [0.9904, 0.6499]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg1[0], x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f154169c-eb91-424d-8721-9674686b66d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = t.tril(t.ones(T, T))\n",
    "wei /= wei.sum(dim=1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d9b6efd-5548-45dd-ad03-e67ca66186d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6900, 0.3497],\n",
       "         [0.5311, 0.2167],\n",
       "         [0.5924, 0.2338],\n",
       "         [0.5401, 0.2883],\n",
       "         [0.5063, 0.2964],\n",
       "         [0.4508, 0.3467],\n",
       "         [0.5050, 0.3476],\n",
       "         [0.5657, 0.3854]],\n",
       "\n",
       "        [[0.4816, 0.2730],\n",
       "         [0.5606, 0.5247],\n",
       "         [0.6979, 0.4842],\n",
       "         [0.5526, 0.5649],\n",
       "         [0.6234, 0.5597],\n",
       "         [0.6425, 0.5787],\n",
       "         [0.6249, 0.6259],\n",
       "         [0.5481, 0.6575]],\n",
       "\n",
       "        [[0.2985, 0.5692],\n",
       "         [0.3423, 0.2985],\n",
       "         [0.3372, 0.2056],\n",
       "         [0.3000, 0.2645],\n",
       "         [0.4126, 0.2850],\n",
       "         [0.4041, 0.2488],\n",
       "         [0.4826, 0.2492],\n",
       "         [0.4450, 0.2248]],\n",
       "\n",
       "        [[0.7437, 0.9064],\n",
       "         [0.4657, 0.5460],\n",
       "         [0.5133, 0.5500],\n",
       "         [0.5575, 0.6121],\n",
       "         [0.4882, 0.6471],\n",
       "         [0.5685, 0.6253],\n",
       "         [0.5439, 0.6299],\n",
       "         [0.5142, 0.6156]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg2 = wei @ x\n",
    "avg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9f1eb4e-b17a-4a06-8f8f-36174b79603f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.allclose(avg2, avg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8902912-d5c8-4f75-b91c-050b86e600b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = t.tril(t.ones(T, T))\n",
    "wei = t.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, -t.inf)\n",
    "wei = nn.functional.softmax(wei, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b03273c-277a-4ef3-9838-be2e0ad7c9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fcd364c6-fff8-4d58-a197-6a2af558db1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg3 = wei @ x\n",
    "t.allclose(avg1, avg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319095f-39d3-44a9-9b31-57180e6f2866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
